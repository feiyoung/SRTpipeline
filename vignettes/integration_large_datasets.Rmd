---
title: "Fast and accurate multiple data integration"
output:
  html_document:
  theme: united
df_print: kable
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---
***

```{r setup, include=FALSE}
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res <- difftime(Sys.time(), now, units = "secs")
      all_times[[options$label]] <<- res
    }
  }
}))
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 95),
  message = FALSE,
  warning = FALSE,
  time_it = TRUE
)
```

# Overview
This tutorial demonstrates how to use `SRTpipeline` (>=0.1.0) to analyze multiple spatially-resolved transcriptomics (SRT) data.  For very large datasets (such as the number of spots greater than 1000k), the  `PRECAST` model can sometimes be prohibitively computationally expensive since this model jointly performs dimension reduction, spatial clustering and embedding alignment. As an alternative, `iSC.MEB` performs spatial clustering and embedding alignment on the principal component scores (PCs) space rather than the gene expression space, which can greatly increase the computational efficiency. In this workflow, based on `iSC.MEB` model, we employ two tips that can further improve its efficiency and runtimes:

* Approximate PCA to obtain PCs
* Choose the number of clusters using prior information or other method


The main one of efficiency improvements are gained in `AddPCA()` by setting the `Method='APCA'`. This means one uses an approximate PCA to obtain the PCs.

First, we load `SRTpipeline`.
```{r init}
library(SRTpipeline)
set.seed(2023)
```



# Dataset
For this tutorial, we will introduce how to create a `SRTProject` object with multiple SRT samples using SRTpipeline that includes an introduction to common analytical workflows for multiple data batches.
Here, we will be taking spatial transcriptomics dataset for human dorsolateral prefrontal cortex (DLPFC) as an example.
There are 12 tissue slices with 3500~4500  spots and 33538 genes that were sequenced on the 10x Visium platform. Our preprocessed data can be downloaded [here](https://github.com/feiyoung/DR-SC.Analysis/blob/main/data/DLPFC_data/), and the raw data can be found [here](https://github.com/LieberInstitute/spatialLIBD).



Next, we  download the data to the current working path for the followed analysis by the following command:
```{r eval=FALSE}
name_ID12 <- as.character(c(151507, 151508, 151509, 151510, 151669, 151670,
                            151671, 151672, 151673, 151674, 151675, 151676))

for(r in seq_along(name_ID12)){
  githubURL <- paste0("https://github.com/feiyoung/DR-SC.Analysis/blob/main/data/DLPFC_data/", name_ID12[r], ".rds?raw=true")
  download.file(githubURL, paste0("dlpfc_", name_ID12[r], ".rds"),mode='wb')
}                            

```


# Pre-processing workflow

Then load to R and prepare for creating the `SRTProject` object.
```{r  eval = FALSE}
dir_file <- "D:/LearnFiles/Research paper/ProPCA/DR-SC.Analysis/data/DLPFC_data/"
name_ID12 <- as.character(c(151507, 151508, 151509, 151510, 151669, 151670,
                            151671, 151672, 151673, 151674, 151675, 151676))
#dir_file <- './dlpfc_'
n_sample <- length(name_ID12)
library(Seurat)
## create count matrix list: note each component has a name, i.e., `ID151672`.
cntList <- list()
## create spatial coordinate matrix 
coordList <- list()
## create metadata list
metadataList <- list()

for(r in 1: n_sample){
  # r <- 1
  message('r = ', r)
  id <- name_ID12[r]
  dlpfc <- readRDS(paste0(dir_file,id, ".rds"))
  sp_count <- dlpfc@assays@data$counts
  meta.data <- data.frame(annotated_label=dlpfc$layer_guess_reordered,
                          row=dlpfc$row, col=dlpfc$col)
  row.names(meta.data) <- colnames(sp_count)
  cntList[[r]] <- sp_count
  metadataList[[r]] <- meta.data
  coordList[[r]] <- cbind(row=dlpfc$row, col=dlpfc$col)
}
names(cntList) <- name_ID12
## create meta data for each data batches. Here we only have one data batch.
sampleMetadata <- data.frame(species=rep("Human", n_sample),
                             tissues=rep('DLPFC', n_sample),
                             donor = rep(1:3, each=4))
row.names(sampleMetadata) <- names(cntList)
## Name of this project
projectName <- "DLPFC12"
```



We check the data by printing it. We can see there are 3500~4500 spots and 33538 genes for each data batch.
```{r  eval = FALSE}
sapply(cntList, dim)
```
Check whether each data batch has the same genes: Yes.
```{r  eval = FALSE}
geneNamesList <- lapply(cntList, row.names)
shared_genes <- Reduce(intersect, geneNamesList)
length(shared_genes)
```


## Create a SRTProject object

Because the gene name is ensembl in this data, we change the genes' ensembl name to symbols for convenience of followed analyses.
```{r  eval = FALSE}
cntList <- lapply(cntList, function(x) x[shared_genes,])
## Use eg.db database: this method is fast
symbol_name <- transferGeneNames(shared_genes, now_name = "ensembl", to_name="symbol", species="Human", Method='eg.db')
for(r in 1:n_sample){
  row.names(cntList[[r]]) <- symbol_name
}
getwd()
```

Next, we start creating SRTProject object. 
```{r  eval = FALSE}
SRTProj <- CreateSRTProject(cntList, coordList, projectName =projectName, metadataList,
    sampleMetadata, min.spots = 20, min.genes = 20,force=F)
SRTProj
```

## Standard workflow
After removing unwanted cells and genes from the dataset, the next step is to normalize the data.  To save RAM memory, normalized values are stored in disk as a `h5file`.
```{r  eval = FALSE}
## Normalizing the data
SRTProj <- normalizeSRT(SRTProj,normalization.method='LogNormalize')
## Choose highly variable features
SRTProj <- selectVariableFeatures(SRTProj,nfeatures = 2000, type = "HVGs", method='vst')
## Calculate the adjcence matrix
SRTProj <- AddAdj(SRTProj, platform = "Visium")

```

## Approximate PCA
After running `AddPCA`, we would see the output of `SRTProj` includes `PCA` in the `Low-dimensional embeddings` field.
```{r, eval = FALSE}
## APCA
SRTProj <- AddPCA(SRTProj, n_comp=15, Method='APCA')
SRTProj
```
## Fast integration using a prior K

Using a proir $K=7$, iSC.MEB model runs faster.
```{r, eval = FALSE}
tic <- proc.time()
SRTProj <- Integrate_iSCMEB(SRTProj, K= 7, reduction = "PCA", init.start=5)
toc <- proc.time()
time_use <- toc[3] - tic[3] # 267 seconds

## or use Louvain clustering to find the number of clusters K
# SRTProj2 <- Cluster_Louvain(SRTProj, resolution = 0.4)
# K <- length(unique(SRTProj2@clusters))
SRTProj
```



## SRT embeddings
To run tSNE in SRTpipeline we use the AddTSNE() function:
```{r, eval = FALSE}
SRTProj <- AddTSNE(SRTProj, n_comp = 2, reduction='aligned.iSC.MEB')
## plot
p_tsne2_cluster <- EmbedPlot(SRTProj, item='cluster', plotEmbeddings = 'tSNE', cols=chooseColors(n_colors = 7), legend.position='bottom', pt_size=0.2)
p_tsne2_batch <- EmbedPlot(SRTProj, item='batch', plotEmbeddings = 'tSNE', cols=chooseColors(palettes_name = 'Light 13',n_colors = 12), legend.position='bottom', pt_size=0.2)
drawFigs(list(p_tsne2_cluster, p_tsne2_batch),layout.dim = c(1,2),
         legend.position = 'bottom')
```



```{r}
sessionInfo()
```
</details>
